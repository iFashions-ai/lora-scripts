{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "\n",
    "sys.path.insert(0, \"../sd-scripts\")\n",
    "import torch\n",
    "from library import train_util, sdxl_train_util, sdxl_model_util\n",
    "from library.sdxl_lpw_stable_diffusion import (\n",
    "    SdxlStableDiffusionLongPromptWeightingPipeline,\n",
    ")\n",
    "\n",
    "from library.video_inpainting_patch import (\n",
    "    VideoInpaintingPatchPipeline,\n",
    "    VideoInpaintingPatch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading settings from /home/longc/data/code/lora-scripts/config/video-example/video-debug.toml...\n",
      "/home/longc/data/code/lora-scripts/config/video-example/video-debug\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import train_network\n",
    "\n",
    "\n",
    "def setup_parser() -> argparse.ArgumentParser:\n",
    "    parser = train_network.setup_parser()\n",
    "    sdxl_train_util.add_sdxl_training_arguments(parser)\n",
    "    return parser\n",
    "\n",
    "\n",
    "parser = setup_parser()\n",
    "\n",
    "argv = [\n",
    "    \"--config_file\",\n",
    "    \"/home/longc/data/code/lora-scripts/config/video-example/video-debug.toml\",\n",
    "]\n",
    "args = parser.parse_args(argv)\n",
    "args = train_util.read_config_from_file(args, parser, argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare tokenizer\n",
      "update token length: 255\n"
     ]
    }
   ],
   "source": [
    "tokenizer = sdxl_train_util.load_tokenizer(args)\n",
    "tokenizers = tokenizer if isinstance(tokenizer, list) else [tokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"preparing accelerator\")\n",
    "accelerator = train_util.prepare_accelerator(args)\n",
    "is_main_process = accelerator.is_main_process\n",
    "\n",
    "# mixed precisionに対応した型を用意しておき適宜castする\n",
    "weight_dtype, save_dtype = train_util.prepare_dtype(args)\n",
    "vae_dtype = torch.float32 if args.no_half_vae else weight_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    load_stable_diffusion_format,\n",
    "    text_encoder1,\n",
    "    text_encoder2,\n",
    "    vae,\n",
    "    unet,\n",
    "    logit_scale,\n",
    "    ckpt_info,\n",
    ") = sdxl_train_util.load_target_model(\n",
    "    args, accelerator, sdxl_model_util.MODEL_VERSION_SDXL_BASE_V1_0, weight_dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load inpainting head\n",
    "inpainting_head = VideoInpaintingPatch(sdxl_model_util.vae_scale_factor).to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdxl_train_util.sample_images(accelerator, args, epoch, global_step, device, vae, tokenizer, text_encoder, unet, inpainting_head=inpainting_head)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
