{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataUnit:\n",
    "    image: str\n",
    "    caption: str\n",
    "    mask: Tuple[str, int]  # (image, index), where mask = image == index\n",
    "    prev_image: str\n",
    "    prev_mask: Tuple[str, int]\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.image = str(self.image)\n",
    "        self.mask = (str(self.mask[0]), int(self.mask[1]))\n",
    "        self.prev_image = str(self.prev_image)\n",
    "        self.prev_mask = (str(self.prev_mask[0]), int(self.prev_mask[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_caption(filename):\n",
    "    filename = Path(filename)\n",
    "    caption_file = filename.parents[1] / \"caption\" / filename.with_suffix(\".txt\").name\n",
    "    if not caption_file.exists():\n",
    "        return None\n",
    "    with open(caption_file, \"r\") as f:\n",
    "        caption = f.read()\n",
    "    return caption\n",
    "\n",
    "\n",
    "def is_adjacent_frames(image1, image2) -> bool:\n",
    "    diff = image1.astype(float) - image2.astype(float)\n",
    "    thresholds = np.asarray([15, 30, 50])\n",
    "    # thresholds = np.asarray([30, 60, 100])\n",
    "    diffs = np.percentile(np.abs(diff), [50, 75, 85])\n",
    "    return np.all(diffs < thresholds)\n",
    "\n",
    "\n",
    "def is_valid_mask(mask1, mask2, idx, min_threshold=0.05, max_threshold=0.3) -> bool:\n",
    "    image_size = mask1.shape[0] * mask1.shape[1]\n",
    "    area1 = (mask1 == idx).sum()\n",
    "    area2 = (mask2 == idx).sum()\n",
    "    return (\n",
    "        min_threshold < area1 / image_size < max_threshold\n",
    "        and min_threshold < area2 / image_size < max_threshold\n",
    "    )\n",
    "\n",
    "\n",
    "def enlarge_mask(mask, index, kscale=0.05):\n",
    "    mask = (mask == index).astype(np.uint8) * 255\n",
    "    if kscale <= 0:\n",
    "        return mask\n",
    "    a = max(int(np.sqrt(mask.shape[0] * mask.shape[1]) * kscale), 11)\n",
    "    return cv2.dilate(mask, np.ones((a, a), np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules of data collection\n",
    "1. Videos with masks and captions\n",
    "2. Two frames |t1 - t2| <= 2\n",
    "3. Two frames |I1 -I2| < x\n",
    "4. Two frames All(area(Mask_i) >= 0.05*Image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = Path(\"/data/video-dataset/VSPW/\")\n",
    "with open(src_dir / \"label_num_dic_final.json\", \"r\") as f:\n",
    "    label2idx = json.load(f)\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "videos = sorted(src_dir.glob(\"data/*\"))\n",
    "\n",
    "validations = {\"415_5FjFtNEBX2I\", \"371_xpPeyi-vFDc\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(video_dir: Path):\n",
    "    cache = {}\n",
    "\n",
    "    def read_image(filename):\n",
    "        if filename not in cache:\n",
    "            cache[filename] = np.array(Image.open(filename))\n",
    "        return cache[filename]\n",
    "\n",
    "    if video_dir.stem in validations:\n",
    "        return []\n",
    "    if not (video_dir / \"mask\").exists() or not (video_dir / \"caption\").exists():\n",
    "        return []\n",
    "    frames = sorted((video_dir / \"origin\").glob(\"*.jpg\"))\n",
    "    n_frames = len(frames)\n",
    "\n",
    "    max_delta = 3\n",
    "    pairs = []\n",
    "    for delta in range(1, max_delta + 1):\n",
    "        pairs += list(zip(range(0, n_frames - delta), range(delta, n_frames)))\n",
    "    dataset = []\n",
    "    for i, j in pairs:\n",
    "        image_i, image_j = frames[i], frames[j]\n",
    "        mask_i, mask_j = (\n",
    "            video_dir / \"mask\" / f\"{image_i.stem}.png\",\n",
    "            video_dir / \"mask\" / f\"{image_j.stem}.png\",\n",
    "        )\n",
    "        caption_i, caption_j = red_caption(image_i), red_caption(image_j)\n",
    "        if not mask_i.exists() or not mask_j.exists() or not caption_i or not caption_j:\n",
    "            continue\n",
    "        # if not is_adjacent_frames(read_image(image_i), read_image(image_j)):\n",
    "        #     continue\n",
    "\n",
    "        mask_i_img = read_image(mask_i)\n",
    "        mask_j_img = read_image(mask_j)\n",
    "        mask_ids = set(np.unique(mask_i_img)) & set(np.unique(mask_j_img))\n",
    "        for idx in mask_ids:\n",
    "            if str(idx) not in idx2label:\n",
    "                continue\n",
    "            if not is_valid_mask(mask_i_img, mask_j_img, idx):\n",
    "                continue\n",
    "            data_unit = DataUnit(\n",
    "                image=frames[j],\n",
    "                caption=caption_j,\n",
    "                mask=(mask_j, idx),\n",
    "                prev_image=frames[i],\n",
    "                prev_mask=(mask_i, idx),\n",
    "            )\n",
    "            dataset.append(data_unit)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3536/3536 [06:09<00:00,  9.57it/s]  \n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "pool = Pool(12)\n",
    "dataset = []\n",
    "for subset in tqdm(pool.imap_unordered(create_dataset, videos), total=len(videos)):\n",
    "    dataset += subset\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(src_dir / \"data_0125.jsonl\", \"w\") as f:\n",
    "    for data_unit in dataset:\n",
    "        data_unit.mask = (data_unit.mask[0], int(data_unit.mask[1]))\n",
    "        data_unit.prev_mask = (data_unit.prev_mask[0], int(data_unit.prev_mask[1]))\n",
    "        f.write(json.dumps(asdict(data_unit)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# temporally create a validation sample\n",
    "video_dir = src_dir / \"data\" / \"371_xpPeyi-vFDc\"\n",
    "dest_dir = Path(\"/home/longc/data/code/lora-scripts/config/video-example-2\")\n",
    "\n",
    "images = sorted(video_dir.glob(\"origin/*\"))\n",
    "masks = sorted(video_dir.glob(\"mask/*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(masks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.unique(mask):\n",
    "    print(idx, idx2label.get(str(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask==91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in tqdm(zip(images, masks), total=len(images)):\n",
    "    dest_image = dest_dir / \"images\" / image.name\n",
    "    dest_mask = dest_dir / \"masks\" / mask.name\n",
    "    dest_image.parent.mkdir(parents=True, exist_ok=True)\n",
    "    dest_mask.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copyfile(image, dest_image)\n",
    "    \n",
    "    mask = enlarge_mask(np.array(Image.open(mask)), index=91, kscale=0)  # bottle_or_cup\n",
    "    cv2.imwrite(str(dest_mask), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
