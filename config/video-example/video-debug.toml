pretrained_model_name_or_path = "/data/SD-models/Stable-diffusion/sd_xl_base_1.0.safetensors"
vae = "/data/SD-models/VAE/sdxl-vae-fp16-fix.safetensors"
v2 = false
# train_data_dir = "/home/longc/data/code/lora-scripts/data/dress-maxmara"
train_data_dir = "/home/longc/data/video-dataset/VSPW"
in_json = "/home/longc/data/video-dataset/VSPW/data.jsonl"
dataset_repeats=1
sample_at_first = true
is_video_inpainting = true

prior_loss_weight = 1
resolution = "1024,1024"
enable_bucket = true
min_bucket_reso = 256
max_bucket_reso = 1024
bucket_reso_steps = 64
output_name = "video-debug"
output_dir = "./output/video-debug"
save_model_as = "safetensors"
save_precision = "fp16"
save_every_n_epochs = 5
max_train_epochs = 20
train_batch_size = 1
gradient_checkpointing = false
network_train_unet_only = false
network_train_text_encoder_only = false
learning_rate = 0.0001
unet_lr = 0.0001
text_encoder_lr = 1e-5
lr_scheduler = "cosine_with_restarts"
lr_warmup_steps = 0
lr_scheduler_num_cycles = 1
optimizer_type = "AdamW8bit"
network_module = "networks.lora"
network_dim = 32
network_alpha = 32
sample_prompts = "/home/longc/data/code/lora-scripts/config/video-example/video-debug-prompt.json"
sample_sampler = "k_dpm_2"
sample_every_n_epochs = 1
# log_with = "tensorboard"
logging_dir = "./logs"
caption_extension = ".txt"
shuffle_caption = true
keep_tokens = 0
max_token_length = 255
flip_aug = false
random_crop = true
seed = 1337
clip_skip = 2
mixed_precision = "fp16"
xformers = true
lowram = false
cache_latents = false
cache_latents_to_disk = false
cache_text_encoder_outputs = false
cache_text_encoder_outputs_to_disk = false
persistent_data_loader_workers = true
